# ğŸ¯ Interview Prep Trainer

> AI-powered **technical interview preparation platform** â€” practice coding, system design, behavioral, and debug questions with **AI-generated questions, grading, hints, and timed modes**. Built with **FastAPI**, **CrewAI**, **React**, **PostgreSQL**, and **Ollama**.

---

## âœ¨ Features

### Core
- **AI-Generated Questions** â€” questions created on-the-fly by an LLM, never repeated
- **Automated Grading** â€” CrewAI multi-agent pipeline (or single-prompt mode) for scoring + feedback
- **Server-Side Answers** â€” correct answers never exposed to the frontend (anti-cheat)
- **Exam History** â€” track past sessions with grades, scores, and detailed review

### Interview Categories
| Category | Description |
|----------|-------------|
| ğŸ’» **Coding** | Write functions and algorithms |
| ğŸ“– **Concept** | Explain technical CS concepts |
| ğŸ› **Debug** | Find and fix bugs in given code |
| ğŸ›ï¸ **System Design** | Design systems and architectures |
| ğŸ¤ **Behavioral** | Situational and teamwork questions (STAR format) |
| ğŸ” **Code Review** | Identify issues and improvements in code |

### Exam Modes
| Mode | Timer | Hints | Purpose |
|------|-------|-------|---------|
| ğŸ“ **Practice** | âŒ | âœ… 3/question | Learn at your own pace |
| â±ï¸ **Timed Exam** | âœ… 5 min/q | âŒ | Simulate interview pressure |
| ğŸ¤ **Mock Interview** | âœ… 7 min/q | âœ… 3/question | Closest to a real interview |

### Hints & Timer
- **Progressive Hints** â€” 3 levels per question (general â†’ specific â†’ near-answer), each costing 15% of max score
- **Countdown Timer** â€” visual urgency states (normal â†’ yellow at 30s â†’ red pulse at 10s), auto-submits on expiry
- **8 Topics** â€” Python, OOP, Data Structures, Algorithms, SQL, JavaScript, Java, Web Dev
- **3 Difficulty Levels** â€” Easy, Medium, Hard
- **2 Question Types** â€” Written (free-text) and Multiple Choice (A/B/C/D)

---

## ğŸ—ï¸ Architecture

```
Browser â†’ React (Vite) :3000
              â†“ HTTP
         FastAPI :8000
         â”œâ”€â”€ API Layer (routes, schemas)
         â”œâ”€â”€ Service Layer (exam, question, grading, hint, health)
         â”œâ”€â”€ Agent Layer (CrewAI: question generator + grading agents)
         â”œâ”€â”€ Repository Layer (SQLAlchemy CRUD)
         â””â”€â”€ Integration Layer (Ollama HTTP client)
              â”œâ”€â”€ PostgreSQL :5432 (questions, exams tables)
              â””â”€â”€ Ollama :11434 (LLM inference)
```

---

## ğŸ“ Project Structure

```
Interview Prep Trainer/
â”œâ”€â”€ docker-compose.yml          # 4-container orchestration
â”œâ”€â”€ .env.example                # Environment template
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py             # FastAPI entry + CORS
â”‚       â”œâ”€â”€ config.py           # Settings from env
â”‚       â”œâ”€â”€ database.py         # SQLAlchemy engine
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â”œâ”€â”€ routes.py       # /exam/start, /exam/answer, /exam/hint, /exams, /topics
â”‚       â”‚   â””â”€â”€ schemas.py      # Pydantic models (CategoryEnum, ModeEnum, HintRequest, etc.)
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â”œâ”€â”€ exam_service.py     # Full exam flow orchestration
â”‚       â”‚   â”œâ”€â”€ question_service.py # LLM question generation
â”‚       â”‚   â”œâ”€â”€ grading_service.py  # Answer grading (crew/single)
â”‚       â”‚   â”œâ”€â”€ hint_service.py     # Progressive hint generation
â”‚       â”‚   â””â”€â”€ health_service.py   # Health checks
â”‚       â”œâ”€â”€ agents/
â”‚       â”‚   â”œâ”€â”€ crew.py                     # CrewAI orchestration
â”‚       â”‚   â”œâ”€â”€ question_generator_agent.py # 6 category-specific prompt templates
â”‚       â”‚   â”œâ”€â”€ grader_agent.py             # Scoring agent
â”‚       â”‚   â”œâ”€â”€ feedback_agent.py           # Feedback agent
â”‚       â”‚   â””â”€â”€ review_agent.py             # Encouragement agent
â”‚       â”œâ”€â”€ repositories/
â”‚       â”‚   â”œâ”€â”€ exam_repository.py
â”‚       â”‚   â”œâ”€â”€ question_repository.py
â”‚       â”‚   â””â”€â”€ submission_repository.py
â”‚       â”œâ”€â”€ integrations/
â”‚       â”‚   â””â”€â”€ ollama_client.py
â”‚       â””â”€â”€ models/
â”‚           â”œâ”€â”€ exam.py          # mode, time_limit_seconds, hints_used, category
â”‚           â”œâ”€â”€ question.py      # category column
â”‚           â””â”€â”€ submission.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx                 # Navbar + page routing
â”‚       â”œâ”€â”€ api/grader.js           # API client (startExam, submitAnswer, requestHint, etc.)
â”‚       â””â”€â”€ components/
â”‚           â”œâ”€â”€ Navbar.jsx          # Navigation bar
â”‚           â”œâ”€â”€ ExamPage.jsx        # Setup (topic, category, mode) â†’ question â†’ result â†’ summary
â”‚           â”œâ”€â”€ QuestionCard.jsx    # Question + answer input + Timer + HintButton
â”‚           â”œâ”€â”€ Timer.jsx           # Countdown timer with urgency states
â”‚           â”œâ”€â”€ HintButton.jsx      # Progressive hint UI (up to 3 hints)
â”‚           â”œâ”€â”€ ExamResult.jsx      # Per-question feedback
â”‚           â”œâ”€â”€ ExamSummary.jsx     # Final exam results
â”‚           â””â”€â”€ ExamHistory.jsx     # Past exam sessions
â”‚
â””â”€â”€ ollama/
    â””â”€â”€ start.sh                    # Model pull script
```

---

## ğŸš€ Quick Start

See [QUICKSTART.md](QUICKSTART.md) for detailed setup instructions.

**TL;DR (Docker):**
```bash
cp .env.example .env
docker compose up --build
```
- Frontend: http://localhost:3000
- Backend: http://localhost:8000
- Health: http://localhost:8000/health

---

## ğŸ”§ Configuration

All settings via `.env` file:

| Variable | Default | Description |
|----------|---------|-------------|
| `DATABASE_URL` | `postgresql://...` | PostgreSQL connection |
| `OLLAMA_MODEL` | `qwen2.5:0.5b` | Default LLM model |
| `GRADING_MODE` | `single` | `crew` (multi-agent) or `single` (direct prompt) |
| `DEFAULT_EXAM_QUESTIONS` | `5` | Questions per exam |
| `GENERATOR_MODEL` | (same as OLLAMA_MODEL) | Optional generator model override |
| `MAX_RETRIES` | `3` | Retry count for LLM calls |

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/exam/start` | Start exam (topic, difficulty, category, mode, num_questions) |
| `POST` | `/exam/answer` | Submit an answer (exam_id, answer) |
| `POST` | `/exam/hint` | Request a hint for current question (exam_id) |
| `GET` | `/exam/{id}` | Get full exam state |
| `GET` | `/exams` | List all exam sessions |
| `GET` | `/topics` | Available topics, difficulties, categories, and modes |
| `GET` | `/health` | Backend + DB + Ollama health |

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------:|
| Frontend | React 18, Vite 5, Lucide React |
| Backend | FastAPI, Python 3.11 |
| AI Agents | CrewAI |
| LLM | Ollama + qwen2.5:0.5b |
| Database | PostgreSQL 16 |
| Container | Docker Compose |

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see [LICENSE](LICENSE) for details.
